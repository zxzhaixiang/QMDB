{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import scipy.signal as sp_signal\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "import hiddenlayer as hl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NCF, self).__init__()\n",
    "        self.config = config\n",
    "        self.user_dim = config['nUsers']\n",
    "        self.movie_dim = config['nMovies']\n",
    "        self.genres_dim = config['nGenres']\n",
    "        \n",
    "        self.g_latent_dim = config['genre_latent_dim']\n",
    "        self.u_latent_dim = config['user_latent_dim']\n",
    "        self.i_latent_dim = config['item_latent_dim']\n",
    "        self.query_dim = config['Query_latent_dim']\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(self.user_dim, self.u_latent_dim, \n",
    "                                           max_norm=1, scale_grad_by_freq = True)\n",
    "        \n",
    "        self.movie_embedding = nn.Embedding(self.movie_dim, self.i_latent_dim,\n",
    "                                           max_norm=1, scale_grad_by_freq = True)\n",
    "\n",
    "        self.genres_layers = nn.Sequential(\n",
    "                                nn.Linear(self.genres_dim, self.g_latent_dim)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "                            nn.Linear(self.u_latent_dim + self.g_latent_dim + self.query_dim + 2, self.u_latent_dim*2),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(self.u_latent_dim*2,self.u_latent_dim),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(self.u_latent_dim,self.u_latent_dim),\n",
    "                            nn.Tanh())\n",
    "        \n",
    "        self.cos_sim = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
    "        \n",
    "    def forward(self, user_id, movie_id, genres, em_query, weekend, hr):\n",
    "        \n",
    "        user_em = self.user_embedding(user_id)\n",
    "        movie_em = self.movie_embedding(movie_id)\n",
    "        \n",
    "        genres_em = self.genres_layers(genres).mean(dim=1, keepdim=True)\n",
    "        \n",
    "        total_em = torch.cat((user_em, genres_em, em_query, weekend.unsqueeze(dim=1), hr.unsqueeze(dim=1)), dim=2)\n",
    "        final_em = self.fc_layers(total_em)\n",
    "        return self.cos_sim(user_em,movie_em)*5, self.cos_sim(final_em,movie_em)*5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nUsers': 4380, 'nMovies': 3868, 'nGenres': 22, 'user_latent_dim': 128, 'item_latent_dim': 128, 'genre_latent_dim': 32, 'Query_latent_dim': 64}\n"
     ]
    }
   ],
   "source": [
    "config = {'nUsers': 4380, 'nMovies': 3868, \n",
    "          'nGenres': 22,\n",
    "          'user_latent_dim': 128, 'item_latent_dim': 128,\n",
    "          'genre_latent_dim': 32, 'Query_latent_dim': 64\n",
    "         }\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_embedding): Embedding(4380, 128, max_norm=1, scale_grad_by_freq=True)\n",
       "  (movie_embedding): Embedding(3868, 128, max_norm=1, scale_grad_by_freq=True)\n",
       "  (genres_layers): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=226, out_features=256, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (cos_sim): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF = NCF(config)\n",
    "CF.load_state_dict(torch.load('./../data/processed_data/cfmodel',map_location=torch.device('cpu')))\n",
    "CF.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embedding = CF.movie_embedding.weight.data.detach().numpy()\n",
    "user_embedding = CF.user_embedding.weight.data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_weight = CF.genres_layers[0].weight.data.detach().numpy()\n",
    "genres_bias = CF.genres_layers[0].bias.data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (256, 226)\n",
      "1 (128, 256)\n",
      "2 (128, 128)\n"
     ]
    }
   ],
   "source": [
    "fc=[{},{},{}]\n",
    "for i in range(3):\n",
    "    fc[i]['weight'] = CF.fc_layers[i*2].weight.data.detach().numpy()\n",
    "    fc[i]['bias'] = CF.fc_layers[i*2].bias.data.detach().numpy()\n",
    "    print(i, fc[i]['weight'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = {'genres_weight':genres_weight,\n",
    "                'genres_bias':genres_bias,\n",
    "                'fc':fc\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list= ['horror', 'fantasy', 'adventure', 'western', 'action', 'war', 'animation', 'comedy', 'family', 'mystery', 'movie', 'documentary', 'fiction', 'romance', 'music', 'history', 'drama', 'science', 'thriller', 'crime', 'tv', 'foreign']\n",
    "genres_dict = dict(zip(genres_list, range(len(genres_list))))\n",
    "\n",
    "model_weights['genres_list'] = genres_list\n",
    "model_weights['genres_dict'] = genres_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/processed_data/keyword_embedding.pkl', 'rb') as f:\n",
    "    kw_embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_set = set(kw_embedding.keys())\n",
    "kw_default_embedding = np.zeros(64)\n",
    "n=0\n",
    "for key in kw_embedding:\n",
    "    kw_default_embedding += kw_embedding[key]\n",
    "    n+=1\n",
    "\n",
    "kw_default_embedding/=n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights['kw_embedding'] = kw_embedding\n",
    "model_weights['kw_default_embedding'] = kw_default_embedding\n",
    "model_weights['kw_set'] = kw_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./../data/processed_data/model_weights','wb') as f:\n",
    "    pickle.dump(model_weights,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_vector(query, model_weights):\n",
    "    kws = [kw.lower() for kw in query.split(' ')]\n",
    "    n = 0\n",
    "    res = np.zeros(64)\n",
    "    for kw in kws:\n",
    "        if kw in model_weights['kw_set']:\n",
    "            res+=model_weights['kw_embedding'][kw]\n",
    "            n+=1\n",
    "    if n==0:\n",
    "        return model_weights['kw_default_embedding']\n",
    "    else:\n",
    "        return res/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_vector(genres, model_weights):\n",
    "    v = np.zeros((22,1))\n",
    "    for g in genres:\n",
    "        v[model_weights['genres_dict'][g]]=1\n",
    "    \n",
    "    return model_weights['genres_weight'].dot(v).squeeze(1)+model_weights['genres_bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_embedding(model_weights, query, user_embedding, genres, isWeekend, hr):\n",
    "    query_embedding = get_query_vector(query, model_weights)\n",
    "    genres_embedding = get_genre_vector(genres, model_weights)\n",
    "    \n",
    "    x = np.concatenate((user_embedding, query_embedding,genres_embedding,np.array([isWeekend,hr])))\n",
    "    \n",
    "    for fc in model_weights['fc']:\n",
    "        x = fc['weight'].dot(x)+fc['bias']\n",
    "        x = np.tanh(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=compute_final_embedding(model_weights, 'hello world', np.zeros(128),['western'], 1, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
