{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('../data/movielens_latest/ml-latest-lean/movies.csv')\n",
    "ratings_df = pd.read_csv('../data/movielens_latest/ml-latest-lean/ratings.csv', compression='gzip') #\n",
    "links_df = pd.read_csv('../data/movielens_latest/ml-latest-lean/links.csv') # \n",
    "tmdb_movies_df = pd.read_csv('../data/tmdb_5000/tmdb_5000_movies.csv') # \n",
    "tmdb_credits_df = pd.read_csv('../data/tmdb_5000/tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get ids to link other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.merge(ratings_df, links_df, on='movieId', how='inner')\n",
    "# assert ratings_df.shape[0]==df1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merge ratings with tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.loc[df1['tmdbId'].notnull(), :]\n",
    "# df1['tmdbId'] = df1['tmdbId'].astype(int)\n",
    "# df2 = pd.merge(df1, tmdb_movies_df, left_on='tmdbId', right_on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Of the total {} ratings we have tmdb information on {} ({:.1f}%).'.format(df1.shape[0], df2.shape[0], 100*df2.shape[0]/df1.shape[0]))\n",
    "# print('Of the total {} movies we have tmdb information on {} ({:.1f}%).'.format(len(df1['movieId'].unique()), len(df2['movieId'].unique()), 100*len(df2['movieId'].unique())/len(df1['movieId'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merge movies with tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(movies_df, links_df, on='movieId', how='inner')\n",
    "assert movies_df.shape[0]==df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc[df1['tmdbId'].notnull(), :]\n",
    "df1['tmdbId'] = df1['tmdbId'].astype(int)\n",
    "df2 = pd.merge(df1, tmdb_movies_df, left_on='tmdbId', right_on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the total 10708 movies we have tmdb information on 3868 (36.1%).\n"
     ]
    }
   ],
   "source": [
    "print('Of the total {} movies we have tmdb information on {} ({:.1f}%).'.format(df1.shape[0], df2.shape[0], 100*df2.shape[0]/df1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merge in credits (cast etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df2, tmdb_credits_df, left_on='tmdbId', right_on='movie_id', how='inner')\n",
    "assert df2.shape[0]==df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_y, keywords, spoken_languages, production_countries, subset_crew, check_cast_id=actor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kw_ctr(df, column, id_name):\n",
    "    cnt = Counter()\n",
    "    for row in df[column]:\n",
    "        row = json.loads(row)\n",
    "        for keyword in row:\n",
    "            cnt[keyword[id_name]] += 1\n",
    "    print('{} has {} unique keywords.'.format(column, len(cnt)))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres_y has 20 unique keywords.\n",
      "keywords has 9393 unique keywords.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-9c5dc434b2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkw_var\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'genres_y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keywords'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spoken_languages'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'production_countries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mkw_ctr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-b6a73ce26082>\u001b[0m in \u001b[0;36mkw_ctr\u001b[1;34m(df, column)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mcnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{} has {} unique keywords.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "for kw_var in ['genres_y', 'keywords', 'spoken_languages', 'production_countries']:\n",
    "    kw_ctr(df3, kw_var, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cnt = Counter()\n",
    "for row in df3['genres_y']:\n",
    "    row = json.loads(row)\n",
    "    for keyword in row:\n",
    "        cnt[keyword['id']] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({16: 201,\n",
       "         35: 1450,\n",
       "         10751: 436,\n",
       "         12: 715,\n",
       "         28: 995,\n",
       "         53: 1088,\n",
       "         18: 1812,\n",
       "         10749: 731,\n",
       "         36: 157,\n",
       "         80: 614,\n",
       "         14: 393,\n",
       "         10752: 116,\n",
       "         9648: 309,\n",
       "         10402: 140,\n",
       "         27: 414,\n",
       "         878: 481,\n",
       "         99: 54,\n",
       "         37: 66,\n",
       "         10769: 8,\n",
       "         10770: 3})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 18, 'name': 'Drama'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qri_automl_clone2",
   "language": "python",
   "name": "qri_automl_clone2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
